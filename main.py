import os
import requests
import random
import feedparser
from datetime import datetime
from bs4 import BeautifulSoup

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL = os.getenv("CHANNEL_USERNAME")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
UNSPLASH_KEY = os.getenv("UNSPLASH_ACCESS_KEY")

# --- –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º ---
USED_LINKS_FILE = "used_links.txt"
USED_IMAGES_FILE = "used_images.txt"

# --- –ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å—Ç—Ä ---
def is_political(text: str) -> bool:
    political_keywords = [
        "—É–∫—Ä–∞–∏–Ω–∞", "—É–∫—Ä–∞—ó–Ω–∞", "ukraine", "zelensky", "–∑–µ–ª–µ–Ω—Å–∫–∏–π", "–∫–∏–µ–≤", "–∫–∏—ó–≤",
        "–¥–æ–Ω–±–∞—Å—Å", "–¥–æ–Ω–µ—Ü–∫", "–ª—É–≥–∞–Ω—Å–∫", "–≤–æ–π–Ω–∞",
        "–≤–æ–µ–Ω–Ω—ã–µ", "–∫–æ–Ω—Ñ–ª–∏–∫—Ç", "—Å–∞–Ω–∫—Ü–∏–∏", "–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è", "—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è"
    ]
    text_lower = text.lower()
    return any(word in text_lower for word in political_keywords)

# --- RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ---
RSS_FEEDS = [
    # AI –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
    "https://www.technologyreview.com/topic/artificial-intelligence/feed",
    "https://deepmind.com/blog/feed/basic",
    "https://openai.com/blog/rss/",
    "http://ai.googleblog.com/feeds/posts/default?alt=rss",
    "https://towardsdatascience.com/feed",
    "https://bair.berkeley.edu/blog/feed.xml",
    "https://machinelearningmastery.com/blog/feed/",
    "https://www.aitrends.com/feed/",
    "https://www.datarobot.com/blog/feed/",
    "http://www.kdnuggets.com/feed",

    # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–π–º–¥–µ–≤
    "https://habr.com/ru/rss/flows/develop/all/?fl=ru",
    "https://www.ixbt.com/export/news.rss",
    "https://kod.ru/feed",
    "https://www.cnews.ru/inc/rss/news.xml",
    "https://stackoverflow.blog/feed/",
    "https://dev.to/feed",
    "https://medium.com/feed/tag/programming",
    "https://techcrunch.com/feed/",
    "https://www.digitaltrends.com/feed/",
    "https://thenextweb.com/feed",
    "https://www.pcworld.com/index.rss",
    "https://hnrss.org/frontpage",
    "https://www.theverge.com/rss/index.xml",
    "https://feeds.arstechnica.com/arstechnica/index",
    "https://xakep.ru/feed/",
    "https://tproger.ru/rss",

    # –ì–µ–π–º–¥–µ–≤ / Unity / Godot
    "https://80.lv/feed/",
    "https://www.gamedeveloper.com/rss.xml",
    "https://godotengine.org/rss.xml",

    # 3D / CAD
    "https://www.blendernation.com/feed/",
    "https://www.cgchannel.com/feed/",
    "https://www.cgtrader.com/blog.rss",
    "https://3ddd.ru/news/rss",
    "https://blogs.solidworks.com/solidworksblog/feed",
    "https://www.blender.org/feed/",

    # –û–±—â–µ–µ
    "https://www.rbc.ru/rss/"
]

# --- –£—Ç–∏–ª–∏—Ç—ã: —Å—Å—ã–ª–∫–∏ ---
def is_posted(link):
    if not os.path.exists(USED_LINKS_FILE):
        return False
    with open(USED_LINKS_FILE, "r", encoding="utf-8") as f:
        return link in f.read()

def mark_posted(link):
    with open(USED_LINKS_FILE, "a", encoding="utf-8") as f:
        f.write(link + "\n")

# --- –£—Ç–∏–ª–∏—Ç—ã: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
def is_image_used(url):
    if not os.path.exists(USED_IMAGES_FILE):
        return False
    with open(USED_IMAGES_FILE, "r", encoding="utf-8") as f:
        return url in f.read()

def mark_image_used(url):
    with open(USED_IMAGES_FILE, "a", encoding="utf-8") as f:
        f.write(url + "\n")

def extract_image_url(entry):
    soup = BeautifulSoup(entry.get("summary", ""), "html.parser")
    img_tag = soup.find("img")
    if img_tag and img_tag.get("src"):
        return img_tag.get("src")
    return None

def get_image_url(entry):
    url = extract_image_url(entry)
    if url and not is_image_used(url):
        mark_image_used(url)
        return url
    return None

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ ---
def get_unique_news():
    for _ in range(10):
        feed = feedparser.parse(random.choice(RSS_FEEDS))
        for entry in feed.entries:
            title = entry.get("title", "")
            summary = entry.get("summary", "")
            link = entry.get("link", "")
            if is_posted(link):
                continue
            if is_political(title) or is_political(summary):
                print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–æ–≤–æ—Å—Ç—å:", title)
                continue
            return {
                "title": title,
                "summary": summary,
                "link": link,
                "source": feed.feed.title if hasattr(feed, "feed") else "–ò—Å—Ç–æ—á–Ω–∏–∫",
                "entry": entry
            }
    return None

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞ ---
def stylize_post(news):
    prompt = f"""
–¢—ã ‚Äî –∞–≤—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ IT, 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: —Å–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π, –∂–∏–≤–æ–π –ø–æ—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ú–∏–Ω–∏–º—É–º 8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ.
- –ò—Å–ø–æ–ª—å–∑—É–π –∂–∏–≤–æ–π, –¥—Ä—É–∂–µ—Å–∫–∏–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è.
- –í –Ω–∞—á–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –∏ –≤—ã–¥–µ–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∂–∏—Ä–Ω—ã–º —Ç–µ–≥–æ–º <b>.
- –ó–∞—Ç–µ–º —É–∫–∞–∂–∏ –¥–∞—Ç—É –∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å —ç–º–æ–¥–∑–∏ üìÖ.
- –î–∞–π –∫—Ä–∞—Ç–∫–æ–µ, –Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Å—É—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π).
- –û–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ –∏–ª–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ —á–∏—Ç–∞—Ç–µ–ª—é.
- –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å –≤–æ–≤–ª–µ–∫–∞—é—â–∏–π –≤–æ–ø—Ä–æ—Å —Å —ç–º–æ–¥–∑–∏ ü§î.
- –°—Å—ã–ª–∫—É –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ –æ—Ñ–æ—Ä–º–ª—è–π —Å —Ç–µ–∫—Å—Ç–æ–º: üìñ –ß–∏—Ç–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ (—á–µ—Ä–µ–∑ —Ç–µ–≥ <a href="...">).
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏–∑–±–µ–≥–∞–π –ø–æ–ª–∏—Ç–∏–∫–∏, –∫–∞–Ω—Ü–µ–ª—è—Ä—â–∏–Ω—ã –∏ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤.

–î–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {news['title']}
–û–ø–∏—Å–∞–Ω–∏–µ: {news['summary']}
–ò—Å—Ç–æ—á–Ω–∏–∫: {news['source']}
–°—Å—ã–ª–∫–∞: {news['link']}
"""

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "openai/gpt-3.5-turbo",
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        r = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, json=data)
        return r.json()['choices'][0]['message']['content']
    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:", e)
        return f"<b>{news['title']}</b>\n{news['link']}"

# --- –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ—Å—Ç–∞ ---
def post_to_telegram(text, image_url):
    url = f"https://api.telegram.org/bot{TOKEN}/sendPhoto"
    payload = {
        "chat_id": CHANNEL,
        "photo": image_url,
        "caption": text,
        "parse_mode": "HTML"
    }
    response = requests.post(url, data=payload)
    if response.status_code != 200:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏:", response.text)

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ ---
def main():
    news = get_unique_news()
    if not news:
        print("üòê –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
        return

    print("üì∞ –ù–æ–≤–æ—Å—Ç—å:", news["title"])
    post_text = stylize_post(news)
    image_url = get_image_url(news["entry"])

    if image_url:
        post_to_telegram(post_text, image_url)
    else:
        print("‚ö†Ô∏è –ö–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–∞")
        requests.post(
            f"https://api.telegram.org/bot{TOKEN}/sendMessage",
            data={"chat_id": CHANNEL, "text": post_text, "parse_mode": "HTML"}
        )

    mark_posted(news["link"])
    print("‚úÖ –ü–æ—Å—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω")

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ---
if __name__ == "__main__":
    main()
